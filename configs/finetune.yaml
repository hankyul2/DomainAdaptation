# 0. project setting & shortcut
project_name: "hankyul2/DomainAdaptation"
short_id: ''

shortcut:
  gpus: '0,1'
  max_epochs: 100
  model_name: 'resnet50'
  dropout: 0.0
  dataset_name: 'cifar10'
  size:
    - 224
    - 224
  batch_size: 32
  num_workers: 4
  lr: 0.03

# 1. load data
data:
  class_path: src.data.cifar.CIFAR
  init_args:
    dataset_name: "cifar10"
    batch_size: 32
    num_workers: 4
    size:
    - 224
    - 224
    data_root: data
    valid_ratio: 0.1

# 2. define model (define other backbone)
model:
  class_path: src.system.finetune.Finetune
  init_args:
    backbone_init:
      model_name: "resnet50"
      pretrained: true

# 3. prepare train tools (optimizer, learning rate scheduler)
optimizer:
  class_path: torch.optim.SGD
  init_args:
    lr: 0.03
    momentum: 0.95
    weight_decay: 0.0005

lr_scheduler:
  class_path: src.lr_schedulers.CosineLR
  init_args:
    max_epochs: 0
    num_step: 0
    warmup_epoch: 1

# 4. train
seed_everything: null
trainer:
  # 4-1. gpu devices
  gpus: null
  accelerator: null
  amp_backend: native

  # 4-2. train setting
  max_epochs: 100
  val_check_interval: 1.0
  check_val_every_n_epoch: 1

  # 4-3. logger & callbacks
  log_every_n_steps: 50

  # 4-4. hyper param tuning
  auto_lr_find: false
  auto_scale_batch_size: false

  # 4-5. for debugging
  fast_dev_run: false
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  limit_predict_batches: 0.05

  # 4-6. etc
  profiler: null
  precision: 32
  multiple_trainloader_mode: max_size_cycle
